# ===========================================
# MANIMATIONS ENVIRONMENT CONFIGURATION
# ===========================================
# Copy this file to .env and fill in your keys
# Note: .env is NOT committed to git (contains secrets)

# ===========================================
# LLM API Keys (Choose at least one)
# ===========================================

# OpenAI (GPT-4o, GPT-4o-mini, etc.)
OPENAI_API_KEY=sk-proj-YOUR_OPENAI_KEY_HERE
OPENAI_MODEL=gpt-4o-mini

# Google Gemini (Alternative to OpenAI)
GEMINI_API_KEY=YOUR_GEMINI_API_KEY_HERE
GEMINI_MODEL=gemini-flash-latest

# DeepSeek (OpenAI-compatible)
DEEPSEEK_API_KEY=YOUR_DEEPSEEK_KEY_HERE
DEEPSEEK_MODEL=deepseek-chat

# ===========================================
# Cloud Storage (Optional - for persistence)
# ===========================================

# Storage backend: local (default), s3, or cloudinary
STORAGE_BACKEND=local

# AWS S3 Configuration (if STORAGE_BACKEND=s3)
AWS_ACCESS_KEY_ID=YOUR_AWS_ACCESS_KEY
AWS_SECRET_ACCESS_KEY=YOUR_AWS_SECRET_KEY
AWS_S3_BUCKET=your-bucket-name
AWS_REGION=us-east-1

# Cloudinary Configuration (if STORAGE_BACKEND=cloudinary)
CLOUDINARY_CLOUD_NAME=your_cloud_name
CLOUDINARY_API_KEY=your_cloudinary_api_key
CLOUDINARY_API_SECRET=your_cloudinary_api_secret

# ===========================================
# Manim & Video Generation Settings
# ===========================================

# Video quality: low, medium, high, production (use 'low' for Railway free tier)
MANIM_QUALITY=low

# Video rendering timeout (seconds)
MANIM_TIMEOUT=900

# Job timeout (seconds) - total time for orchestration + rendering
JOB_TIMEOUT=1200

# Maximum concurrent jobs
MAX_CONCURRENT_JOBS=1

# Resolution (WxH)
MANIM_RESOLUTION=1920x1080

# Frames per second
MANIM_FPS=30

# ===========================================
# Server Configuration
# ===========================================

# Server host and port (Railway sets HOST=0.0.0.0, PORT=8000 automatically)
HOST=0.0.0.0
PORT=8000

# ===========================================
# Voice Synthesis (Optional)
# ===========================================

# Voice engine: pyttsx3 (default/offline), gtts, elevenlabs, system
VOICE_ENGINE=pyttsx3

# Voice rate (words per minute)
VOICE_RATE=160

# Voice volume (0.0 to 1.0)
VOICE_VOLUME=0.9

# Enable voice caching to save API calls
VOICE_CACHE_ENABLED=true

# Directory for caching generated voices
VOICE_CACHE_DIR=./voice_cache

# ElevenLabs API (if VOICE_ENGINE=elevenlabs)
# ELEVENLABS_API_KEY=YOUR_ELEVENLABS_KEY_HERE
# ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM

# ===========================================
# Logging & Debugging
# ===========================================

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# LLM timeout (seconds)
LLM_TIMEOUT=30

# Voice generation timeout (seconds)
VOICE_TIMEOUT=15

# Video rendering timeout (seconds)
RENDER_TIMEOUT=300

# ===========================================
# ffmpeg Configuration
# ===========================================

# Leave commented; moviepy auto-detects from system PATH
# On Railway: ffmpeg installed via Docker (apt-get install ffmpeg)
# On local Windows: uncomment and set path if auto-detection fails
# FFMPEG_BINARY=/usr/bin/ffmpeg

# ===========================================
# Optional: Local LLM (Ollama)
# ===========================================

# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama2

